[{"content":"\u003cp\u003eIt tuns out the \u003ca href=\"https://www.humanlabsaintpierre.org/\"\u003eHumanLab Saint-Pierre\u003c/a\u003e was particularly busy this year. How busy ? Busy enough to hold its first \u0026ldquo;hackathon like\u0026rdquo; event, the so-called \u003ccode\u003efabrikarium\u003c/code\u003e.\nSince \u003ca href=\"https://myhumankit.org/en/home/\"\u003eHumanLabs are FabLabs specially dedicated to assistive technologies\u003c/a\u003e, their fabrikarium events consist of \u003ccode\u003eprototyping workshops dedicated to tackle disability-related issues\u003c/code\u003e.\nPeople from all over France came together in 4 teams of 10 makers, whether they be engineers, researchers, healthcare professionnals, students, retiree, etc.\nAnyone would be welcomed to contribute, as long as they have an some brain time to grant, a helping hand to give and a big warm heart.\u003c/p\u003e\n\u003cp\u003eSince its a first (and undoubtedly not the last), it beneficiated from a pretty generous media coverage.\u003c/p\u003e\n\u003ch2 id=\"fabrikarium\"\u003eFabrikarium\u003c/h2\u003e\n\u003cp\u003eThe goal here is to resolve specific major issues in every-day life for the disabled : it may be the difficulty of driving a wheelchair when it rains, eating with full autonomy at any time or any place, or communicating easily with others when needed. It is about \u003ccode\u003eneed-led\u003c/code\u003e approaches : we start from real-life specific issues (that may be related to one specific pathology) that we actually can witness, and we are building our way up into a more global solution that can benefit to other disabilities. \u003ccode\u003eAccesibility is the guiding principle\u003c/code\u003e : solutions have to be wisely thougt and engineered enough to be cheap, easily reproducible and easy to use. If you want to put some buzzwords on it, we\u0026rsquo;re not only talking about \u003ccode\u003eopen source\u003c/code\u003e, but \u003ccode\u003efrugal creativity\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eIt was a 3-days event. With a neat organizing team, we had the opportunity to work with the support of people from various organisations, including \u003ca href=\"https://www.ariane.group/en/\"\u003eArianeGroup\u003c/a\u003e, \u003ca href=\"https://www.inria.fr/en\"\u003eINRIA\u003c/a\u003e and \u003ca href=\"https://fortil.group/\"\u003eFortil Group\u003c/a\u003e. Of course, people from other HumanLabs in France also came to give a hand.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/fabrikarium_team.jpg\" alt=\"Personal team\" title=\"This was my team !\"\u003e\u003c/p\u003e\n\u003ch2 id=\"the-projects\"\u003eThe projects\u003c/h2\u003e\n\u003cp\u003e4 projects were presented around 4 teams of 10 people. Those 10 were all makers with different backgrounds - that is part of the charm. Full documentation is not ready yet, but I will update this article as soon as possible when available. Meanwhile, \u003ca href=\"https://wikilab.myhumankit.org/index.php?title=Accueil\"\u003ethe WikiLab website\u003c/a\u003e lists all of future, present and past projects led in all HumanLabs.\u003c/p\u003e\n\u003cp\u003eMine was about wheelchair augmentation for a young freshman student. Affected by involuntary muscle contractions induced by dystonia, he could not control his wheelchair with his hands. Instead, he did it with his chin, thanks to an arm support which positioned a joystick under his head. The problem was someone else had to move it either in front of him for him to write or use a device, or on his side to be enable him to freely move around without the risk of stumbling over obstacles. Our main goal was to find a \u003ccode\u003esecure and easy-to-use solution\u003c/code\u003e to give him back his full autonomy. What we did consisted of \u003ccode\u003eusing robotics to automate the movement of his arm support at will\u003c/code\u003e, using an arcade push button (for full robustness over the years) on the side of his head that control a small linear actuator. We moduralized the whole mechanical assembly of his system as well, in order to enable easy and plug-n-play maintenance. Finally, we also had time to test an \u003ccode\u003eembedded voice user interface\u003c/code\u003e which worked pretty well.\u003c/p\u003e\n\u003ch2 id=\"next-steps\"\u003eNext steps\u003c/h2\u003e\n\u003cp\u003eOf course, the prototypes we developed will evolve over time and are not limited to this event. The idea was to give either a boost or a flying start so we can rapidly know which solutions best suit the interested parties. Once targeted, we can dress a full roadmap in which we can fit more prototype testing over time, under various situations. In my project\u0026rsquo;s case, it was clear that \u003ccode\u003eintroducing a microcontroler-based system opened the door of many exciting possibilites\u003c/code\u003e : home automation, new human-computer interactions for devices control, augmented environment awareness\u0026hellip; Knowing how driving and inspiring the project initiators (the affected student and his dad) were, I do not have a single doubt of how evolved they will make their system grow.\u003c/p\u003e\n\u003cp\u003eI was curious to witness how a project can evolve in just 3 days in such a setting. Of course, I did not expect to see our prototypes growing so fast at that advanced level. But honestly, I was more surprised of how much the event was not about ideas and prototypes growth, but about meeting great, crazy-talented, and thoughtful people. Try and stop me from attending next year !\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/fabrikarium_whole_team.jpg\" alt=\"Whole team\" title=\"The whole makers team !\"\u003e\u003c/p\u003e\n","description":null,"image":"/images/fabrikarium.jpg","permalink":"https://ko-sinus.github.io/projects/2023-06-8-fabrikarium/","title":"Augmented Wheelchair"},{"content":"\u003cp\u003eThis was the first \u003ccode\u003ehuman-computer interaction for healthcare\u003c/code\u003e project I made.\nIt was intended for an 11 years old French child named Emilie.\u003c/p\u003e\n\u003cp\u003eBefore I go into the beautiful details behind it all, here is a video promoting our success :\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PhL7JxOnTew\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\u003cp\u003eAt the time, I was working at the \u003ca href=\"https://www.humanlabsaintpierre.org/\"\u003eHumanLab Saint-Pierre\u003c/a\u003e\n(actually, if on their homepage you see a child holding a weird thing with a motor attached to it, this is Emilie !\nI am the man behind her at her right - the man on the left is the chief research engineer of the HumanLab).\nThe most beautiful aspect of this project is that \u003ccode\u003eit is entirely open-source\u003c/code\u003e - and that is why I can share all of these details with you.\u003c/p\u003e\n\u003ch2 id=\"humanlabs-\"\u003eHumanLabs ?\u003c/h2\u003e\n\u003cp\u003eThe open-source thing is actually a common aspect to all HumanLabs projects. If you don\u0026rsquo;t know what HumanLabs are, you can find more about them \u003ca href=\"https://myhumankit.org/en/home/\"\u003ehere\u003c/a\u003e.\nHumanLabs basically consist of Fablabs that are specifically dedicated to \u003ccode\u003eassistive technologies\u003c/code\u003e.\nTheir goal is to encourage people with physical disabilities to conceive and manufacture their own assistive technologies, using a classic fablab\u0026rsquo;s equipment (3D printing, open-source electronics, \u0026hellip;).\u003c/p\u003e\n\u003cp\u003eNot only did I had the chance to work within one of them, but I actually worked in a specific one :\nthe HumanLab Saint-Pierre, located in the South of France, works closely with the \u003ca href=\"https://www.institut-st-pierre.com/\"\u003eInstitut Saint-Pierre paediatric hospital\u003c/a\u003e, and thus benefits from a dedicated medical team support (occupational therapists, ortho-prosthetists, doctors, \u0026hellip;).\nThis cross-disciplinary team setting was key for the success of this project, as it linked \u003ccode\u003etraditional orthosis manufacturing\u003c/code\u003e, \u003ccode\u003e3D printing\u003c/code\u003e and \u003ccode\u003eelectronics\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"short-context\"\u003eShort context\u003c/h2\u003e\n\u003cp\u003eEmilie is a timid but lovely child who has an injured arm : \u003ccode\u003eher right arm is paralysed from her shoulder to her wrist\u003c/code\u003e, keeping her from any elbow motion from one side.\nBefore this project started, she had a traditional mechanical orthosis - she had to lock her injured arm with the other one on one specific position.\nMy role there was to propose a way to enable the elbow motion in the most natural way possible.\nFortunatly since she could still move her fingers to grip something on her right hand, I was able to propose \u003ccode\u003ean arm positioning system using the very same injured limb\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"disneys-magic\"\u003eDisney\u0026rsquo;s magic\u003c/h2\u003e\n\u003cp\u003eAfter reviewing some interaction technologies, I decided to use \u003ccode\u003ecapacitive sensing\u003c/code\u003e since it also resolved the direction control problem - flexion or extension.\nAs this project was not \u0026lsquo;childish\u0026rsquo; enough, I based the touch sensing technology on \u003ca href=\"https://la.disneyresearch.com/publication/touche-enhancing-touch-interaction-on-humans-screens-liquids-and-everyday-objects/\"\u003eDisney Research Lab\u0026rsquo;s Touch√© project\u003c/a\u003e,\nmainly because of its hardware simplicity (only passive components). Hardware simplicity enables efficient scalability and reproductibility at low cost, both essential for any open-source project.\nHuge thanks to Danish makers \u003ca href=\"http://blog.dzl.dk/\"\u003eDZL\u003c/a\u003e, \u003ca href=\"http://www.hobye.dk/\"\u003eMads Hobye\u003c/a\u003e and \u003ca href=\"http://illutron.dk/\"\u003eIllutron\u003c/a\u003e for their preliminary work on bringing Disney\u0026rsquo;s research into the maker world.\u003c/p\u003e\n\u003cp\u003eThe final solution I designed consists of a \u003ccode\u003etouch-activated mechanism which moves a linear actuator for arm positioning\u003c/code\u003e (inspiration from \u003ca href=\"https://sites.google.com/site/ourkidscandoanything/\"\u003eLorelei\u0026rsquo;s project\u003c/a\u003e). \u003cem\u003eThe final control commands\u003c/em\u003e uses 2 types of input : \u003ccode\u003eshort-click\u003c/code\u003e or \u003ccode\u003elong press\u003c/code\u003e. A long press input moves the arm, while a short-click input defines the direction : it goes up if one short click is detected before a long press, goes down is there is no short click before a long press.\u003c/p\u003e\n\u003cp\u003eIf you want full documentation on this, you can \u003ca href=\"https://wikilab.myhumankit.org/index.php?title=Projets:Orth%C3%A8se_de_Coude_Robotis%C3%A9e\"\u003edirectly head to this link\u003c/a\u003e.\nFor non-french speakers, \u003ca href=\"https://github.com/ko-sinus/emilie-arm\"\u003esource files are on my Github\u003c/a\u003e.\u003c/p\u003e\n","description":null,"image":"/images/orthosis.jpg","permalink":"https://ko-sinus.github.io/projects/2021-07-24-assistive-robotic-arm/","title":"Pediatric Robotic Arm"},{"content":"\u003cp\u003e(\u003cstrong\u003eUpdate : the paper has been published !\u003c/strong\u003e Check it out here : \u003ca href=\"https://www.frontiersin.org/articles/10.3389/fnrgo.2023.1147211/full\"\u003epaper link\u003c/a\u003e.)\u003c/p\u003e\n\u003cp\u003eI had the opportunity to work at \u003ca href=\"https://www.tudelft.nl/\"\u003eTU Delft\u003c/a\u003e, the oldest technical university in The Netherlands, which also happens to be ranked among the top 10 engineering and technology universities in the world. It may sound cool, but the coolest was the proposed project : I was offered to work on the \u003ccode\u003eethical decision making\u003c/code\u003e process of autonomous systems, with a focus on \u003ccode\u003eautonomous vehicles\u003c/code\u003e. I was there to work on the understanding and modeling of decision-making mechanisms incorporating \u003ccode\u003enormative uncertainty\u003c/code\u003e (uncertainty on which ethical theory is the most appropriate) for autonomous systems, and how to take \u003ccode\u003ehuman values and credences towards ethical principles\u003c/code\u003e (both at an individual and society\u0026rsquo;s scales) into account when making critical decisions. How cool is that ? Well, our work was based on the very popular MIT\u0026rsquo;s \u003ca href=\"https://www.moralmachine.net/\"\u003eMoral Machine experiment\u003c/a\u003e, whose results were \u003ca href=\"https://www.nature.com/articles/s41586-018-0637-6\"\u003epublished in Nature in 2018\u003c/a\u003e. So, pretty cool.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://pbs.twimg.com/media/Fd0GOYKXgAAggJ8?format=jpg\u0026amp;name=large\" alt=\"AiTech comic strip\" title=\"AiTech comic strip. Fun but important stuff\"\u003e\n| \u003cb\u003eImage Credits - AiTech communication\u003c/b\u003e|\u003c/p\u003e\n\u003ch2 id=\"the-aitech-initiative\"\u003eThe AiTech initiative\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://www.tudelft.nl/aitech\"\u003eAiTech\u003c/a\u003e is TU Delft‚Äôs interdisciplinary research program on awareness, concepts, and design \u0026amp; engineering of autonomous technology under \u003ccode\u003emeaningful human control\u003c/code\u003e. What is meaningful human control, you ask ? Well, they defined meaningful control as a way to affect the outcome so that humans can take responsibility and act upon it. This can be pretty hard when it comes to artificial intelligence as it is closely embedded into a system and often act as a black box. The whole challenge is then about designing well-balanced human-AI systems such that meaningful human control is maintained, and humans are still responsible for the end result. It is all about keeping the benefits of automation while maintaining human responsibility and values.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://d2k0ddhflgrk1i.cloudfront.net/Websections/AiTech/NEW/IMG_6254.jpg\" alt=\"AiTech\" title=\"First AiTech symposium. Clearly some hot topics.\"\u003e\n| \u003cb\u003eImage Credits - First AiTech symposium\u003c/b\u003e|\u003c/p\u003e\n\u003cp\u003eThere is a lot of involved researchers from very different backgrounds around this project : \u003ccode\u003edesigners\u003c/code\u003e, \u003ccode\u003ecomputer scientists\u003c/code\u003e, \u003ccode\u003eethicists\u003c/code\u003e, \u0026hellip; I personally worked under the supervision of assistant Prof. \u003ca href=\"https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/interactive-intelligence/people/current-group-members/luciano-cavalcante-siebert\"\u003eLuciano Cavalcante Siebert\u003c/a\u003e and Prof. \u003ca href=\"https://catholijnjonker.nl/\"\u003eCatholjn Jonker\u003c/a\u003e (actually, they are mentionning me \u003ca href=\"https://www.tudelft.nl/aitech/output#:~:text=Supervision%20of%20internship%20(student%20from%C2%A0%20IMT%20Mines%20Ales%2C%20France)%20on%20%E2%80%9CEthical%20decision%20making%20for%20autonomous%20systems%20considering%20moral%20uncertainty%E2%80%9D%20%40EEMCS%20%2D%20Luciano%2C%20Catholijn\"\u003ehere\u003c/a\u003e). They have developed several approaches to contribute to the field of \u003ccode\u003emachine ethics\u003c/code\u003e : \u003ccode\u003epredictability of humain-AI interactions\u003c/code\u003e, managing one\u0026rsquo;s \u003ccode\u003etrust in autonomous system\u003c/code\u003e, keeping \u003ccode\u003ehuman rights in AI systems\u003c/code\u003e, \u0026hellip; My project was about automating \u003ccode\u003edecision making under moral uncertainty\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"moral-uncertainty\"\u003eMoral uncertainty\u003c/h2\u003e\n\u003cp\u003eArtificial agents are increasingly capable of interacting with their environment, self-learning, and making autonomous decisions. However, as they directly impact human lives, we may witness undesired consequences of their actions. In the field of autonomous vehicles, this is particularly relevant due to \u003ccode\u003enon-forgiving situations\u003c/code\u003e, where decisions that can irreversibly impact lives must be made in a split-second. Because we want those systems to be beneficial for individuals and society, there is a need for their decision-making process to be ‚Äúgood‚Äù, ‚Äúright‚Äù or ‚Äúfair‚Äù : in other terms, we need these systems to match our morality. The main question this reasoning rises is the following : whose morality exactly are we talking about? Who gets to decide which behaviour an artificial agent has to follow in order to be more ethical? As you guessed it, there is no universal agreement on what it means to be morally ‚Äúgood‚Äù. Several initiatives have proposed a converging set of ethical principles for ethical AI. However, systematic approaches to embedding these principles in autonomous systems face the challenge of disagreement between different ethical theories, i.e., \u003ccode\u003ethe problem of moral uncertainty\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://upload.wikimedia.org/wikipedia/commons/3/37/Moral_Machine_Screenshot.png\" alt=\"The Moral Machine experiment\" title=\"The Moral Machine experiment. Tough choice, huh ?\"\u003e\n| \u003cb\u003eImage Credits - The Moral Machine experiment, MIT\u003c/b\u003e|\u003c/p\u003e\n\u003cp\u003eOur approach aims to contribute to the development of ethical AI that can respond to \u003ccode\u003eindividual moral perception\u003c/code\u003e, facilitating meaningful human control to avoid responsibility gaps. We tested our method using MIT‚Äôs Moral Machine Experiment as a data source : our goal was to repurpose the well-known trolley dilemma towards means to understand and estimate \u003ccode\u003eone‚Äôs credence towards normative ethical theories\u003c/code\u003e. This enables us to incorporate moral uncertainty by proposing a decision-making system that combines, \u003ccode\u003evia voting schemes\u003c/code\u003e, different ethical theories according to predicted credence levels of human agents.\u003c/p\u003e\n\u003ch2 id=\"discussions\"\u003eDiscussions\u003c/h2\u003e\n\u003cp\u003eWhile the Moral Machine experiment was criticized for its improbable realness or its relevance to morality, we argue among others that the experiment results are not to be taken directly and have broader applications as they are opening discussions concerning individuals preferences or value-sensitive design processes. The main purpose of our work was not to evaluate whether such situations can happen, but rather about giving a better understanding of ethical human decision-making process and proposing an implementation of human preferences regarding ethics into autonomous systems behaviour. Our study actually showed that the use of voting schemes in order to aggregate one\u0026rsquo;s preferences leads to more ethical decisions than original choices. We can therefore conclude that it is possible to make a decision that considers both a given set of ethical principles and human preferences.\u003c/p\u003e\n\u003cp\u003eThere is so much things that can be further discussed here. But at the end of the day, all we want is to live in a world that is aligned with our values. AI is very new to our world, and people think there is much that remains to learn about them. While I agree with them, \u003ccode\u003eI think there is much more that remains for them to learn about us\u003c/code\u003e.\u003c/p\u003e\n","description":null,"image":"/images/moralmachine.png","permalink":"https://ko-sinus.github.io/projects/2020-07-02-moraluncertainty/","title":"Moral Uncertainty for AI"},{"content":"\u003cp\u003eThis is one of my biggest \u003ccode\u003enon-technological initiative\u003c/code\u003e. During my 1st year as a graduate student, I gathered a few of my classmates, some of my university\u0026rsquo;s administrators, some CEOs and regional actors and a few brillant minds and I reunited them for a \u003ccode\u003eTEDx conference\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eBelow are the official recordings from TEDxTalks YouTube channel. There\u0026rsquo;s a lot of topics covered in there : \u003ccode\u003ebiomimicry\u003c/code\u003e, \u003ccode\u003eemotional AI\u003c/code\u003e, \u003ccode\u003eclimate change\u003c/code\u003e or even \u003ccode\u003eprosthetics\u003c/code\u003e. How they all gather together, you ask ? Well, it\u0026rsquo;s all about the theme : \u003ccode\u003e¬´ Alter-Natifs ¬ª\u003c/code\u003e (french for ¬´ alternatives ¬ª), which is intentionally spelled as a combination of the words \u003ccode\u003e¬´ alter ¬ª\u003c/code\u003e (that refers to \u0026ldquo;the other\u0026rdquo;) and \u003ccode\u003e¬´ natifs ¬ª\u003c/code\u003e (french for ¬´ natives ¬ª). It literally means ¬´ born different ¬ª, or ¬´ born in another way ¬ª. Under this theme \u003ccode\u003eI wanted to illustrate change\u003c/code\u003e, from its mechanism to its consequences, at different level and through different perspectives. I find the whole process of change very interesting as it leads to very specific and sometimes opposite behaviours. Just think about the last 20 years and how rapidly our society evolved looking at technology, economy, environment, individuals, ‚Ä¶ Note that \u003ccode\u003eI am talking about evolution, which is unfortunately not necessarily linked to progress\u003c/code\u003e.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/videoseries?list=PLOiyO46VJXTJgWL5rVUj1krZ4-17XhWLZ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\u003ch2 id=\"ted-and-tedx\"\u003eTED and TEDx\u003c/h2\u003e\n\u003cp\u003eYou might first want to know about TED and TEDx conferences (I understood they were quite popular but encountered several people who have never heard of them while working on this project). Basically, TED is a gloabl non-profit organisation that promotes \u003ccode\u003eideas worth sharing\u003c/code\u003e (see what I did here) under short (\u0026lt;18min) \u003ca href=\"https://www.ted.com/about/conferences\"\u003eengaging and inspiring talks\u003c/a\u003e. Their official events usually involve a lot of major global players from different expertise areas (I won\u0026rsquo;t name-drop here, I think is best for you to form your own judgement). This is their main activity ; one other responsibility they hold is to allow individuals to organise their own local version of a TED conference, \u003ca href=\"https://www.ted.com/about/programs-initiatives/tedx-program\"\u003etherefore named TEDx\u003c/a\u003e. It is a great community, and a great opportunity for you to share to the whole world the everyday genius minds around you.\u003c/p\u003e\n\u003cp\u003eThis exactly what I wanted to do at this time : gathering a few people around some values we considered worth knowing, and sharing to others what inspired us around us.\u003c/p\u003e\n\u003ch2 id=\"how-it-all-started\"\u003eHow it all started\u003c/h2\u003e\n\u003cp\u003eAn official TEDx event thus requires a TEDx license granted to an individual. I ended up holding one, and quite frankly, the story behind is nothing but ordinary. It all started after a normal grad student\u0026rsquo;s day as I was searching for some tutorials to watch from a chemical class I was taking. Of course as usual when it comes to YouTube videos, I ended up watching anything else from what I was looking for. I stumbled upon \u003ca href=\"https://www.youtube.com/watch?v=Ek4V62VJU7c\"\u003ea TEDx talk from a french actor\u003c/a\u003e - he was basically sharing how he got where he was, with nothing but dreams and perseverance. It\u0026rsquo;s actually a popular TEDx talk, but to me the most inspiing thing was that he was my age (still is, obviously).\u003c/p\u003e\n\u003cp\u003eWhat he was doing didn\u0026rsquo;t actually matter (you guessed it, I am not a cinema-goer). What really mattered was that he was doing it well enough so that I could actually see him on stage, giving his speech while I was still confused about \u003ca href=\"https://en.wikipedia.org/wiki/Spinodal_decomposition#:~:text=7%5D%5B8%5D-,Cahn%E2%80%93Hilliard%20model%20for%20spinodal%20decomposition,-%5Bedit%5D\"\u003espinodal decomposition\u003c/a\u003e. So when I asked myself what could I do with all of this inspiration and I saw that he intervened during a \u003ca href=\"https://tedxmcgill.org/\"\u003eTEDxMcGill\u003c/a\u003e event, the answer was pretty straightfoward. The next morning, I talk of it with one of my classmates, and he agreed it could be cool to have one in our engineering school. Because we had a gap in our schedules, we directly went to our university administrators office. In less than an hour, we were pitching this idea to the studies director. When I asked him \u0026ldquo;Why don\u0026rsquo;t we have one already\u0026rdquo;, I undestood \u0026ldquo;for no reason\u0026rdquo; as an answer. So I gathered a team, contacted TED and said I wanted to do just that. \u003ccode\u003eTEDxIMTMinesAles was born\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca data-flickr-embed=\"true\" href=\"https://www.flickr.com/photos/186411459@N02/49445548591/in/album-72157712848289357/\" title=\"TEDx IMT Mines Al√®s 2020\"\u003e\u003cimg src=\"https://live.staticflickr.com/65535/49445548591_9497ab197f_z.jpg\" width=\"500\" height=\"332\" alt=\"TEDx IMT Mines Al√®s 2020\"\u003e\u003c/a\u003e\u003cscript async src=\"//embedr.flickr.com/assets/client-code.js\" charset=\"utf-8\"\u003e\u003c/script\u003e\u003c/p\u003e\n\u003ch2 id=\"how-it-all-ended\"\u003eHow it all ended\u003c/h2\u003e\n\u003cp\u003eSince \u003ccode\u003eit was the first TEDx event of the city\u003c/code\u003e, \u003ccode\u003eand the second one at a regional level\u003c/code\u003e, there was a lot of different stakeholders involved. Everyone had their own interest in participating in such an event. I realised what it meant to be lead organiser of a multi-disciplinary public event : being commited into something that is bigger that us, and having the responsibility to make decisions. These decisions were sometimes hard, sometimes easy, but these never were completely obvious as it impacted different people at different levels. This is key for making pertinent decisions : \u003ccode\u003emanaging consequences\u003c/code\u003e. The more predictible the better, so we can evaluate risks and build bigger and stronger things on top.\u003c/p\u003e\n\u003cp\u003eI have fond memories of it as it enabled me to met incredible people who was doing incredbile work. To this day, TEDx events from my university are still organised every year by different teams of students. This is a pretty cool legacy.\u003c/p\u003e\n\u003cp\u003eNote that I could organise conferences without the TEDx label. However, I knew I couldn\u0026rsquo;t engage with so many stakeholders without introducing something they\u0026rsquo;d at least partially already know. Also, recording talks was important to me. By the way, you can follow TEDxIMTMinesAles\u0026rsquo;s future events \u003ca href=\"https://www.ted.com/tedx/events?autocomplete_filter=TEDxIMTMinesAles\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eJust like anything in this world, the difficult thing here was to put everything in place to be able to give life to what we had in mind. But this is actually key. Because in the end, it is all about how much effort you want to put it in. This is what makes what you care about really different, and \u003ccode\u003ethis is how you can make it different\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca data-flickr-embed=\"true\" href=\"https://www.flickr.com/photos/186411459@N02/49445526901/in/album-72157712848289357/\" title=\"TEDxIMTMinesAl√®s 2020\"\u003e\u003cimg src=\"https://live.staticflickr.com/65535/49445526901_ffa6520cf7_z.jpg\" width=\"500\" height=\"332\" alt=\"TEDxIMTMinesAl√®s 2020\"\u003e\u003c/a\u003e\u003cscript async src=\"//embedr.flickr.com/assets/client-code.js\" charset=\"utf-8\"\u003e\u003c/script\u003e\u003c/p\u003e\n","description":null,"image":"/images/tedx.jpg","permalink":"https://ko-sinus.github.io/projects/2020-01-16-tedximtminesales/","title":"TEDxIMTMinesAles"}]