<!DOCTYPE html>
<html>

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta http-equiv="Accept-CH" content="DPR, Viewport-Width, Width">
<link rel="icon" href=/fav.png type="image/gif">


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload"
      as="style"
      href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
>
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
      media="print" onload="this.media='all'" />
<noscript>
  <link
          href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
          rel="stylesheet">
</noscript>


<link rel="stylesheet" href="/css/font.css" media="all">



<meta property="og:title" content="Moral Uncertainty for AI" />
<meta property="og:description" content="I had the opportunity to work at TU Delft, the oldest technical university in The Netherlands, which also happens to be ranked among the top 10 engineering and technology universities in the world. It may sound cool, but the coolest was the proposed project : I was offered to work on the ethical decision making process of autonomous systems, with a focus on autonomous vehicles. I was there to work on the understanding and modeling of decision-making mechanisms incorporating normative uncertainty (uncertainty on which ethical theory is the most appropriate) for autonomous systems, and how to take human values and credences towards ethical principles (both at an individual and society&rsquo;s scales) into account when making critical decisions." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ko-sinus.github.io/projects/2020-07-02-moraluncertainty/" /><meta property="article:section" content="projects" />
<meta property="article:published_time" content="2020-07-02T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-07-02T00:00:00+00:00" /><meta property="og:site_name" content="Koji Andria" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Moral Uncertainty for AI"/>
<meta name="twitter:description" content="I had the opportunity to work at TU Delft, the oldest technical university in The Netherlands, which also happens to be ranked among the top 10 engineering and technology universities in the world. It may sound cool, but the coolest was the proposed project : I was offered to work on the ethical decision making process of autonomous systems, with a focus on autonomous vehicles. I was there to work on the understanding and modeling of decision-making mechanisms incorporating normative uncertainty (uncertainty on which ethical theory is the most appropriate) for autonomous systems, and how to take human values and credences towards ethical principles (both at an individual and society&rsquo;s scales) into account when making critical decisions."/>


<link rel="stylesheet" href="/bootstrap-5/css/bootstrap.min.css" media="all"><link rel="stylesheet" href="/css/header.css" media="all">
<link rel="stylesheet" href="/css/footer.css" media="all">


<link rel="stylesheet" href="/css/theme.css" media="all">




<style>
    :root {
        --text-color: #101112;
        --text-secondary-color: #101112;
        --background-color: #f2f4f5;
        --secondary-background-color: #64ffda;
        --primary-color: #c4062e;
        --secondary-color: #f8f9fa;

         
        --text-color-dark: #e4e6eb;
        --text-secondary-color-dark: #b0b3b8;
        --background-color-dark: #18191a;
        --secondary-background-color-dark: #212529;
        --primary-color-dark: #528926;
        --secondary-color-dark: #212529;
    }
    body {
        font-size: 1rem;
        font-weight: 400;
        line-height: 1.5;
        text-align: left;
    }

    html {
        background-color: var(--background-color) !important;
    }

    body::-webkit-scrollbar {
        width: .5em;
        height: .5em;
        background-color: var(--background-color);
    }
    
    ::-webkit-scrollbar-track {
        box-shadow: inset 0 0 6px var(--background-color);
        border-radius: 1rem;
    }
    
    ::-webkit-scrollbar-thumb {
        border-radius: 1rem;
        background-color: var(--secondary-color);
        outline: 1px solid var(--background-color);
    }

    #search-content::-webkit-scrollbar {
        width: .5em;
        height: .1em;
        background-color: var(--background-color);
    }
</style>

<meta name="description" content="">
<link rel="stylesheet" href="/css/single.css">


<script defer src="/fontawesome-5/all-5.15.4.js"></script>

  <title>
Moral Uncertainty for AI | Koji Andria

  </title>
</head>

<body class="light">
  
  
<script>
    let localStorageValue = localStorage.getItem("pref-theme");
    let mediaQuery = window.matchMedia('(prefers-color-scheme: dark)').matches;

    switch (localStorageValue) {
        case "dark":
            document.body.classList.add('dark');
            break;
        case "light":
            document.body.classList.remove('dark');
            break;
        default:
            if (mediaQuery) {
                document.body.classList.add('dark');
            }
            break;
    }
</script>



<header>
    <nav class="pt-3 navbar navbar-expand-lg animate">
        <div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5">
            
            <a class="navbar-brand primary-font text-wrap" href="/">
                
                <img src="/fav.png" width="30" height="30"
                    class="d-inline-block align-top">
                Koji Andria
                
            </a>

            

            
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarContent"
                aria-controls="navbarContent" aria-expanded="false" aria-label="Toggle navigation">
                <svg aria-hidden="true" height="24" viewBox="0 0 16 16" version="1.1" width="24" data-view-component="true">
                    <path fill-rule="evenodd" d="M1 2.75A.75.75 0 011.75 2h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 2.75zm0 5A.75.75 0 011.75 7h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 7.75zM1.75 12a.75.75 0 100 1.5h12.5a.75.75 0 100-1.5H1.75z"></path>
                </svg>
            </button>

            
            <div class="collapse navbar-collapse text-wrap primary-font" id="navbarContent">
                <ul class="navbar-nav ms-auto text-center">
                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#about" aria-label="about">
                            About Me
                        </a>
                    </li>
                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#experience"
                            aria-label="experience">
                            Experience
                        </a>
                    </li>
                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#education"
                            aria-label="education">
                            Education
                        </a>
                    </li>
                    

                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#achievements"
                            aria-label="achievements">
                            Achievements
                        </a>
                    </li>
                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#contact"
                            aria-label="contact">
                            Contact
                        </a>
                    </li>
                    

                    
                    
                    
                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/projects" title="Projects posts">
                            
                            Projects
                        </a>
                    </li>
                    
                    

                    
                    <li class="nav-item navbar-text">
                        
                        <div class="text-center">
                            <button id="theme-toggle">
                                <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                                    <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                                </svg>
                                <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                                    <circle cx="12" cy="12" r="5"></circle>
                                    <line x1="12" y1="1" x2="12" y2="3"></line>
                                    <line x1="12" y1="21" x2="12" y2="23"></line>
                                    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                                    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                                    <line x1="1" y1="12" x2="3" y2="12"></line>
                                    <line x1="21" y1="12" x2="23" y2="12"></line>
                                    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                                    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                                </svg>
                            </button>
                        </div>
                    </li>
                    

                </ul>

            </div>
        </div>
    </nav>
</header>
<div id="content">
<section id="single">
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-sm-12 col-md-12 col-lg-9">
        <div class="pr-lg-4">
          <div class="title mb-5">
            <h1 class="text-center mb-4">Moral Uncertainty for AI</h1>
            <div class="text-center">
               
              <small>|</small>
              Jul 2, 2020

              
              <span id="readingTime">
                min read
              </span>
              
            </div>
          </div>
          
          <div class="featured-image">
            <img class="img-fluid" src="/images/moralmachine.png" alt="Moral Uncertainty for AI">
          </div>
          
          <article class="page-content  p-2">
          <p>I had the opportunity to work at <a href="https://www.tudelft.nl/">TU Delft</a>, the oldest technical university in The Netherlands, which also happens to be ranked among the top 10 engineering and technology universities in the world. It may sound cool, but the coolest was the proposed project : I was offered to work on the <code>ethical decision making</code> process of autonomous systems, with a focus on <code>autonomous vehicles</code>. I was there to work on the understanding and modeling of decision-making mechanisms incorporating <code>normative uncertainty</code> (uncertainty on which ethical theory is the most appropriate) for autonomous systems, and how to take <code>human values and credences towards ethical principles</code> (both at an individual and society&rsquo;s scales) into account when making critical decisions. How cool is that ? Well, our work was based on the very popular MIT&rsquo;s <a href="https://www.moralmachine.net/">Moral Machine experiment</a>, whose results were <a href="https://www.nature.com/articles/s41586-018-0637-6">published in Nature in 2018</a>. So, pretty cool.</p>
<p><img src="https://pbs.twimg.com/media/Fd0GOYKXgAAggJ8?format=jpg&amp;name=large" alt="AiTech comic strip" title="AiTech comic strip. Important but fun stuff">
| <b>Image Credits - AiTech communication</b>|</p>
<h2 id="the-aitech-initiative">The AiTech initiative</h2>
<p><a href="https://www.tudelft.nl/aitech">AiTech</a> is TU Delft’s interdisciplinary research program on awareness, concepts, and design &amp; engineering of autonomous technology under <code>meaningful human control</code>. What is meaningful human control, you ask ? Well, they defined meaningful control as a way to affect the outcome so that humans can take responsibility and act upon it. This can be pretty hard when it comes to artificial intelligence as it is closely embedded into a system and often act as a black box. The whole challenge is then about designing well-balanced human-AI systems such that meaningful human control is maintained, and humans are still responsible for the end result. It is all about keeping the benefits of automation while maintaining human responsibility and values.</p>
<p><img src="https://d2k0ddhflgrk1i.cloudfront.net/Websections/AiTech/NEW/IMG_6254.jpg" alt="AiTech" title="First AiTech symposium. Clearly some hot topics.">
| <b>Image Credits - First AiTech symposium</b>|</p>
<p>There is a lot of involved researchers from very different backgrounds around this project : <code>designers</code>, <code>computer scientists</code>, <code>ethicists</code>, &hellip; I personally worked under the supervision of assistant Prof. <a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/interactive-intelligence/people/current-group-members/luciano-cavalcante-siebert">Luciano Cavalcante Siebert</a> and Prof. <a href="https://catholijnjonker.nl/">Catholjn Jonker</a> (actually, they are mentionning me <a href="https://www.tudelft.nl/aitech/output#:~:text=Supervision%20of%20internship%20(student%20from%C2%A0%20IMT%20Mines%20Ales%2C%20France)%20on%20%E2%80%9CEthical%20decision%20making%20for%20autonomous%20systems%20considering%20moral%20uncertainty%E2%80%9D%20%40EEMCS%20%2D%20Luciano%2C%20Catholijn">here</a>). They have developed several approaches to contribute to the field of <code>machine ethics</code> : <code>predictability of humain-AI interactions</code>, managing one&rsquo;s <code>trust in autonomous system</code>, keeping <code>human rights in AI systems</code>, &hellip; My project was about automating <code>decision making under moral uncertainty</code>.</p>
<h2 id="moral-uncertainty">Moral uncertainty</h2>
<p>Artificial agents are increasingly capable of interacting with their environment, self-learning, and making autonomous decisions. However, as they directly impact human lives, we may witness undesired consequences of their actions. In the field of autonomous vehicles, this is particularly relevant due to <code>non-forgiving situations</code>, where decisions that can irreversibly impact lives must be made in a split-second. Because we want those systems to be beneficial for individuals and society, there is a need for their decision-making process to be “good”, “right” or “fair” : in other terms, we need these systems to match our morality. The main question this reasoning rises is the following : whose morality exactly are we talking about? Who gets to decide which behaviour an artificial agent has to follow in order to be more ethical? As you guessed it, there is no universal agreement on what it means to be morally “good”. Several initiatives have proposed a converging set of ethical principles for ethical AI. However, systematic approaches to embedding these principles in autonomous systems face the challenge of disagreement between different ethical theories, i.e., <code>the problem of moral uncertainty</code>.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/3/37/Moral_Machine_Screenshot.png" alt="The Moral Machine experiment" title="The Moral Machine experiment. Tough choice, huh ?">
| <b>Image Credits - The Moral Machine experiment, MIT</b>|</p>
<p>Our approach aims to contribute to the development of ethical AI that can respond to <code>individual moral perception</code>, facilitating meaningful human control to avoid responsibility gaps. We tested our method using MIT’s Moral Machine Experiment as a data source : our goal was to repurpose the well-known trolley dilemma towards means to understand and estimate <code>one’s credence towards normative ethical theories</code>. This enables us to incorporate moral uncertainty by proposing a decision-making system that combines, <code>via voting schemes</code>, different ethical theories according to predicted credence levels of human agents.</p>
<h2 id="discussions">Discussions</h2>
<p>While the Moral Machine experiment was criticized for its improbable realness or its relevance to morality, we argue among others that the experiment results are not to be taken directly and have broader applications as they are opening discussions concerning individuals preferences or value-sensitive design processes. The main purpose of our work was not to evaluate whether such situations can happen, but rather about giving a better understanding of ethical human decision-making process and proposing an implementation of human preferences regarding ethics into autonomous systems behaviour. Our study actually showed that the use of voting schemes in order to aggregate one&rsquo;s preferences leads to more ethical decisions than original choices. We can therefore conclude that it is possible to make a decision that considers both a given set of ethical principles and human preferences.</p>
<p>There is so much things that can be further discussed here. But at the end of the day, all we want is to live in a world that is aligned with our values. AI is very new to our world, and people think there is much that remains to learn about them. While I agree with them, <code>I think there is much more that remains for them to learn about us</code>.</p>

          </article>
        </div>
      </div>
      <div class="col-sm-12 col-md-12 col-lg-3">
        <div class="sticky-sidebar">
          
          <aside class="toc">
              <h5>
                Table Of Contents
              </h5>
              <div class="toc-content">
                <nav id="TableOfContents">
  <ul>
    <li><a href="#the-aitech-initiative">The AiTech initiative</a></li>
    <li><a href="#moral-uncertainty">Moral uncertainty</a></li>
    <li><a href="#discussions">Discussions</a></li>
  </ul>
</nav>
              </div>
          </aside>
          

          

          
          <aside class="social">
            <h5>Social</h5>
            <div class="social-content">
              <ul class="list-inline">
                <li class="list-inline-item text-center">
                  <a target="_blank" href="https://twitter.com/share?text=Moral%20Uncertainty%20for%20AI&url=https%3a%2f%2fko-sinus.github.io%2fprojects%2f2020-07-02-moraluncertainty%2f">
                    <i class="fab fa-twitter"></i>
                  </a>
                </li>
                <li class="list-inline-item text-center">
                  <a target="_blank" href="https://api.whatsapp.com/send?text=Moral%20Uncertainty%20for%20AI: https%3a%2f%2fko-sinus.github.io%2fprojects%2f2020-07-02-moraluncertainty%2f">
                    <i class="fab fa-whatsapp"></i>
                  </a>
                </li>
                <li class="list-inline-item text-center">
                  <a target="_blank" href='mailto:?subject=Moral%20Uncertainty%20for%20AI&amp;body=Check%20out%20this%20site https%3a%2f%2fko-sinus.github.io%2fprojects%2f2020-07-02-moraluncertainty%2f'>
                    <i class="fa fa-envelope"></i>
                  </a>
                </li>
              </ul>
            </div>
          </aside>
          
        </div>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12 col-lg-9 p-4">
        
      </div>
    </div>
  </div>
  <button class="p-2 px-3" onclick="topFunction()" id="topScroll">
    <i class="fas fa-angle-up"></i>
  </button>
</section>


<div class="progress">
  <div id="scroll-progress-bar" class="progress-bar" role="progressbar" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div>
</div>
<Script src="/js/scrollProgressBar.js"></script>


<script>
  var topScroll = document.getElementById("topScroll");
  window.onscroll = function() {scrollFunction()};

  function scrollFunction() {
    if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
      topScroll.style.display = "block";
    } else {
      topScroll.style.display = "none";
    }
  }

  function topFunction() {
    document.body.scrollTop = 0;
    document.documentElement.scrollTop = 0;
  }
</script>


<script src="/js/readingTime.js"></script>



  </div><footer>
    <div class="container py-3" id="recent-posts">
    
</div><div class="text-center pt-2">
    

    

    

    

    
</div><div class="container py-4">
    <div class="row justify-content-center">
        <div class="col-md-4 text-center">
            <div class="pb-2">
                <a href="https://ko-sinus.github.io" title="Koji Andria">
                    <img alt="Footer logo" src="/fav.png"
                        height="40px" width="40px">
                </a>
            </div>
            &copy; 2023  All rights reserved
            <div class="text-secondary">
                Made with
                <span class="text-danger">
                    &#10084;
                </span>
                and
                <a href="https://github.com/gurusabarish/hugo-profile" target="_blank"
                    title="Designed and developed by gurusabarish">
                    Hugo Profile
                </a>
            </div>
        </div>
    </div>
</div></footer><script src="/bootstrap-5/js/bootstrap.bundle.min.js"></script>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

    var tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]'))
    var tooltipList = tooltipTriggerList.map(function (tooltipTriggerEl) {
        return new bootstrap.Tooltip(tooltipTriggerEl)
    })

</script>









  <section id="search-content" class="py-2">
    <div class="container" id="search-results"></div>
  </section>
</body>

</html>